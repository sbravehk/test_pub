name: Build and Deploy linux python wheels to PyPI

on:
  workflow_dispatch:
  push:
    tags:
      - 'v*'

jobs:
  build_manylinux_wheels:
    name: Build linux wheels with ${{ matrix.py_ver_prefix }}-${{ matrix.linux_arch }}-${{ matrix.device }}
    runs-on: ubuntu-20.04
    strategy:
      matrix:
        py_ver_prefix: [cp36, cp37, cp38, cp39, cp310]
        linux_arch: [x86_64, i686, aarch64, s390x, ppc64le] #the maximum timeout of a job is 360 minutes, which is easy to time out, so we compile different system architectures separately.
        device: [cpu, gpu]
        exclude:
          - linux_arch: i686
            device: gpu
          - linux_arch: aarch64
            device: gpu
          - linux_arch: s390x
            device: gpu
          - linux_arch: ppc64le
            device: gpu
      fail-fast: false
    timeout-minutes: 1440

    steps:
    - name: Check out source code
      uses: actions/checkout@v3

    - name: Get python path
      run: |
        sudo apt update
        sudo apt install -y jq
        echo PY_PATH=$(echo '{"cp36": "cp36-cp36m", "cp37": "cp37-cp37m", "cp38": "cp38-cp38", "cp39": "cp39-cp39", "cp310": "cp310-cp310", "cp311": "cp311-cp311", "cp312": "cp312-cp312", "pp37": "pp37-pypy37_pp73", "pp38": "pp38-pypy38_pp73", "pp39": "pp39-pypy39_pp73"}' | jq .${{matrix.py_ver_prefix}} ) >> $GITHUB_ENV

    - name: Set up QEMU
      uses: docker/setup-qemu-action@v2

    - name: Get necessary envs that the current process has access to
      id: set_env 
      run: |
        from os import environ, sched_getaffinity

        # get the cpu cores
        num_cpus = len(sched_getaffinity(0))
        output_file = environ["GITHUB_OUTPUT"]
        with open(output_file, "a", encoding="utf-8") as output_stream:
            output_stream.write(f"count={num_cpus}\n")

        # using gcc-8 for x86_64 and gpu stage
        if "${{ matrix.device }}" == "gpu" and "${{ matrix.linux_arch }}" == "x86_64":
            with open(output_file, "a", encoding="utf-8") as output_stream:
                output_stream.write(f"cmake_args=\"-DCMAKE_C_COMPILER=/opt/rh/devtoolset-8/root/usr/bin/gcc -DCMAKE_CXX_COMPILER=/opt/rh/devtoolset-8/root/usr/bin/g++\"\n")
      shell: python

    - name: Build wheels
      uses: pypa/cibuildwheel@v2.13.1
      env:
        CIBW_ENVIRONMENT: >
          LD_LIBRARY_PATH=/opt/python/${{ env.PY_PATH }}/lib:/opt/python/cp38-cp38/lib:/opt/python/cp310-cp310/lib
          CMAKE_BUILD_PARALLEL_LEVEL=${{ steps.set_env.outputs.count }}
          GIT_SHA=${{ github.sha }}
          CMAKE_ARGS=${{ steps.set_env.outputs.cmake_args }}
          DEVICE=${{ matrix.device }}
        CIBW_BUILD_VERBOSITY: 1
        CIBW_BUILD: ${{ matrix.py_ver_prefix }}-*
        CIBW_SKIP: "*musllinux*" #disable musllinux now
        CIBW_ARCHS_LINUX: ${{ matrix.linux_arch }}
        CIBW_MANYLINUX_X86_64_IMAGE: smartbrave/manylinux2014_x86_64_shared_python:latest
        CIBW_MANYLINUX_I686_IMAGE: smartbrave/manylinux2014_i686_shared_python:latest
        CIBW_MANYLINUX_AARCH64_IMAGE: smartbrave/manylinux2014_aarch64_shared_python:latest
        CIBW_MANYLINUX_PPC64LE_IMAGE: smartbrave/manylinux2014_ppc64le_shared_python:latest
        CIBW_MANYLINUX_S390X_IMAGE: smartbrave/manylinux2014_s390x_shared_python:latest
        # cuda11 is used by FFmpeg and BabitMF, which is not support gcc-9+, so we remove the default gcc installed by manylinux and reinstall gcc/g++ 8 for x86_64 and gpu stage. On the other hand, devtoolset-8-xxx is not exist on i686 platform.
        CIBW_BEFORE_ALL_LINUX: >
          if [ ! -d "3rd_party/json" ]; then (cd 3rd_party && tar xzvf 3rd_party.tar.gz && rm -rf ffmpeg_bin) fi &&
          if [ ! -d "bmf/hml/third_party/pybind11" ]; then (cd bmf/hml/third_party && tar xzvf third_party.tar.gz) fi &&
          if [ ${{ matrix.device }} == "gpu" ] && [ ${{ matrix.linux_arch }} == "x86_64" ]; then mv /opt/rh/devtoolset-10{,.bak} && yum -y install devtoolset-8-{gcc,gcc-c++} && export PATH=/opt/rh/devtoolset-8/root/usr/bin:${PATH}; fi &&
          (./scripts/build_ffmpeg.sh ${{ matrix.device }})
        CIBW_REPAIR_WHEEL_COMMAND_LINUX: >
          auditwheel show {wheel} &&
          echo "auditwheel show {wheel} done..." &&
          tmp_dir=$(mktemp -d) &&
          unzip -d ${tmp_dir} {wheel} &&
          auditwheel -v repair $(ldd ${tmp_dir}/bmf/lib/* ${tmp_dir}/*.libs/* | awk '{if(NF>1){print $1}}' | grep "avdevice\|avfilter\|avformat\|avcodec\|postproc\|swresample\|swscale\|avutil\|cuda" | sort | uniq | awk '{printf(" --exclude %s", $1);}') -w {dest_dir} {wheel} &&
          rm -rf ${tmp_dir}

    - uses: actions/upload-artifact@v3
      with:
        path: ./wheelhouse/*.whl


  upload_all_to_pypi:
    needs: [build_manylinux_wheels]
    runs-on: ubuntu-latest # pypa/gh-action-pypi-publish only support linux
    #if: github.event_name == 'release' && github.event.action == 'published'
    steps:
    - uses: actions/download-artifact@v3
      with:
        name: artifact
        path: dist

    - name: Publish package distributions to TestPyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      #if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags')
      with:
        print-hash: true
        verbose: true
        skip-existing: true
        repository-url: https://test.pypi.org/legacy/
        user: __token__
        password: ${{ secrets.TEST_PYPI_TOKEN }}
        #packages-dir: wheelhouse/
